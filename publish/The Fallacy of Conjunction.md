---
title: "The Fallacy of Conjunction"
created: May 12, 2023
---

The "Fallacy of Conjunction," as demonstrated by Kahneman and Tversky, is an example of how our perceptions can be skewed by vivid, readily available information. The researchers showed that people often make judgments that defy logic, influenced by the compelling nature of the details presented to them. In essence, our brain sometimes fails to rationally process information, especially when it's presented in a particular light or aligned with our pre-existing beliefs. This mental bias leads us to overreach in our conclusions, often tying in unrelated factors merely because they coincide with what we already presume to be true (See: [[Correlation vs Causation]]).

This can be particularly problematic when we're trying to make sense of adverse situations (see: [[Using flawed models leads to suboptimal decisions and repeated mistakes]]). When confronted with something we find objectionable, our instinct is often to assume that it was done with deliberate intent ([[Hanlon's Razor]]). However, this is akin to assuming that a woman is more likely to be both a bank teller and a feminist, rather than just a bank teller (also known as [[The Linda Problem]]). Such assumptions, fueled by vivid and emotionally charged information, can cause our minds to malfunction in their assessments.

---
### References

Parrish, S. (2019). _The Great Mental Models: General thinking concepts. Latticework Publishing_.

> Thus, Kahneman and Tversky showed that students would, with enough vivid wording, assume it more likely that a liberal-leaning woman was both a feminist and a bank teller rather than simply a bank teller. They called it the “Fallacy of Conjunction.” With this experiment, and a host of others, Kahneman and Tversky exposed a sort of tic in our mental machinery: we’re deeply affected by vivid, available evidence, to such a degree that we’re willing to make judgments that violate simple logic. We over-conclude based on the available information. We have no trouble packaging in unrelated factors if they happen to occur in proximity to what we already believe.

> If we present the evidence in a certain light, the brain malfunctions. It doesn’t weigh out the variables in a rational way

### Related Notes
**Source**: [[The Great Mental Models]]
**Tags**: #EvergreenNote
